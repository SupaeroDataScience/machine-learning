{"cells":[{"cell_type":"markdown","metadata":{"id":"K9vywTX5oKK3"},"source":["# Explainable AI"]},{"cell_type":"markdown","metadata":{"id":"oh8vtnIQoNUk"},"source":["This notebook contains :\n","- Intuition behind LIME\n","- LIME for text\n","- LIME for images\n","- Intuition behind SHAP\n","- SHAP on tabular data"]},{"cell_type":"markdown","metadata":{"id":"c19d3a84"},"source":["## LIME [(Ribeiro .al 2016)](https://arxiv.org/abs/1602.04938)\n","\n","### Intuition\n","*Intuitively, an explanation is a local linear approximation of the model's behaviour. While the model may be very complex globally, it is easier to approximate it around the vicinity of a particular instance. While treating the model as a black box, we perturb the instance we want to explain and learn a sparse linear model around it, as an explanation.*\n","\n","![](https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/lime.png)"]},{"cell_type":"markdown","metadata":{"id":"a1245910"},"source":["## Algorithm steps\n","The different steps computed by the algorithm are the following :\n","\n","### 1. Creation of a neighbourhood around the instance :\n","- Data samples are generated by applying perturbations around the instance following a normal distribution\n","- A weight is allocated to every sample with regard to its proximity to the instance. This is the crucial step. The instance explanations may differ a lot with regard to the kernel used to compute the weights. 2 variables are at stake here, the kernel function and the kernel width :\n","  - the kernel function $k$ :\n","  $$k(d, k_w) = exp(\\frac{-d^2}{k_w})$$  \n","  where $$d = \\sqrt{\\sum_{i}^{} (y_i - x_i)^2}$$\n","  - the kernel width $k_w$ :\n","$$k_w = 0.75*\\sqrt{n_f}$$\n","with $n_f$ the number of features in the train set.\n","\n","$k$ and $k_w$ are 2 parameters of our LIME function and can be customised.\n","\n","An example of the impact of the kernel width on the instance explanation :\n","\n","![](https://christophm.github.io/interpretable-ml-book/lime_files/figure-html/fig-lime-fail-1.png)\n","\n","### 2. Generate the samples labels\n","Make black-box model predictions on the newly generated neighbourhood dataset to generate the associated labels.\n","\n","### 3. Fit a linear model on the samples\n","A linear model is then fitted to this labeled data in order to generate our local linear model which corresponds to our instance explanation\n"]},{"cell_type":"markdown","metadata":{"id":"c9e6aa82"},"source":["# LIME for text\n","\n","LIME for text data has one major difference with LIME for tabular data : the way the samples are generated and their weights computed. Let's take again the first step of the algorithm, illustrated with a YouTube comments Spam classification model.\n","\n","|| CONTENT      | CLASS |\n","|-----------| ----------- | ----------- |\n","|267| PSY is a good guy      | 0       |\n","|173| For Christmas Song visit my channel! ;)   | 1        |\n","\n","### 1. Creation of a neighbourhoods around the instance :\n","\n","Data samples are generated by randomly removing some words from the instance text. The neighbourhood dataset is a dataset a binary features, where the value is 1 if the corresponding word is included and 0 if it has been removed.\n","\n","| For |\tChristmas\t| Song |\tvisit |\tmy |\tchannel! |\t;) |\n","| -- | -- | -- | -- | -- | -- | -- |\n","|1|0|1|1|0|0|1|\n","|0|1|1|1|1|0|1|\n","|1|0|0|1|1|1|1|\n","|1|0|1|1|1|1|1|\n","|0|1|1|1|0|0|1|\n","\n","A weight is allocated to every sample with regard to its proximity to the instance. With LIME for text, the weight is calculated with the same kernel than for tabular data, with a default kernel width of 25 (kernel width can be customised).\n","\n","| For |\tChristmas\t| Song |\tvisit |\tmy |\tchannel! |\t;) | weight |\n","| -- | -- | -- | -- | -- | -- | -- | -- |\n","|1|0|1|1|0|0|1|0.89|\n","|0|1|1|1|1|0|1|0.92|\n","|1|0|0|1|1|1|1|0.92|\n","|1|0|1|1|1|1|1|0.96|\n","|0|1|1|1|0|0|1|0.89|\n","\n","### 2. Generate the samples labels\n","\n","This second step is very close to the one for tabular data. The class 1 probability is calculated for every sample using the black-box model's predictions.\n","\n","| For |\tChristmas\t| Song |\tvisit |\tmy |\tchannel! |\t;) | weight | prob |\n","| -- | -- | -- | -- | -- | -- | -- | -- | -- |\n","|1|0|1|1|0|0|1|0.89|0.17|\n","|0|1|1|1|1|0|1|0.92|0.17|\n","|1|0|0|1|1|1|1|0.92|0.99|\n","|1|0|1|1|1|1|1|0.96|0.99|\n","|0|1|1|1|0|0|1|0.89|0.17|\n","\n","### 3. Fit a linear model on the samples\n","This third step remains the same, a linear model is then fitted to this labeled data in order to generate our local linear model which corresponds to our instance explanation."]},{"cell_type":"markdown","metadata":{"id":"DxoRJURjLRlC"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8v1uXHEZbNoj"},"outputs":[],"source":["!pip install lime\n","\n","import pandas as pd\n","import re\n","from IPython.display import HTML\n","from sklearn import (\n","    feature_extraction,\n","    linear_model,\n","    metrics,\n","    pipeline,\n",")\n","from lime.lime_text import LimeTextExplainer"]},{"cell_type":"markdown","metadata":{"id":"xCj9RMkrLtAt"},"source":["## Data"]},{"cell_type":"code","source":["df_train = pd.read_csv(\"/content/sample_data/train.csv\")\n","df_test = pd.read_csv(\"/content/sample_data/test.csv\")"],"metadata":{"id":"7Fh8f54LOQKg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFkAwyxaOGp8"},"outputs":[],"source":["# UNCOMMENT IF RUNNING THE NOTEBOOK LOCALLY\n","\n","# df_train = pd.read_csv(\"../data/ag_news/train.csv\")\n","# df_test = pd.read_csv(\"../data/ag_news/test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9O6SqomTD57"},"outputs":[],"source":["df_train.columns = map(str.lower, df_train.columns)\n","df_test.columns = map(str.lower, df_test.columns)\n","\n","df_train = df_train.rename(columns={'class index': 'target'})\n","df_test = df_test.rename(columns={'class index': 'target'})\n","\n","target_mapping = {\n","    1: \"World\",\n","    2: \"Sports\",\n","    3: \"Business\",\n","    4: \"Sci/Tech\"\n","}\n","\n","class_names = target_mapping.values()\n","\n","df_train"]},{"cell_type":"markdown","metadata":{"id":"cjNEMXGxMlZm"},"source":["## TF-IDF Vectorizer & Logistic regression"]},{"cell_type":"code","source":["Define a pipeline with a TF-IDF vectorizer and a Logistic regression model"],"metadata":{"id":"EsClmjCyRaND"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Az4950_FNh9"},"outputs":[],"source":["#TF-IDF\n","tfidf_vc = ### TODO ###\n","\n","# Logistic regression\n","model = ### TODO ###\n","\n","# Pipeline\n","pipe = pipeline.Pipeline(\n","    steps=[\n","       ### TODO ###\n","    ]\n",")\n","\n","pipe.fit(df_train[\"description\"], df_train.target)\n","\n","y_pred = pipe.predict(df_test[\"description\"])"]},{"cell_type":"markdown","metadata":{"id":"nx1AOaegMxBD"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EKdpt5jFCls"},"outputs":[],"source":["y_pred = pipe.predict(df_test[\"description\"])\n","print(metrics.classification_report(df_test.target, y_pred, target_names=class_names))\n","metrics.ConfusionMatrixDisplay.from_predictions(df_test.target, y_pred, cmap=\"Blues\", display_labels=class_names)"]},{"cell_type":"markdown","metadata":{"id":"8eGjREQaNbuH"},"source":["## LIME explainability"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1C6x8-4HNHH"},"outputs":[],"source":["idx = ### TODO ###\n","\n","explainer = LimeTextExplainer(class_names = class_names)\n","exp = explainer.explain_instance(\n","    df_test[\"description\"][idx],\n","    pipe.predict_proba,\n","    num_features = 10,\n","    top_labels=4\n",")\n","\n","HTML(exp.as_html(text=df_test[\"description\"][idx]))"]},{"cell_type":"markdown","metadata":{"id":"de135198"},"source":["# LIME for image\n","\n","LIME algorithm for images works a little differently than for tabular data and text. Indeed, perturbing individual pixels one by one will not really change the prediction because more than one pixel contribute to one class.\n","\n","\n","\n","## Algorithm steps\n","The different steps computed by the algorithm are the following :\n","\n","### 1. Creation of superpixels :\n","The alorithm first requires to generate \"superpixels\" which are composed of contigous pixels that share properties such as texture or color distribution.This step is crucial for the generation of the LIME explanation since perturbation of superpixels is used to identify which of the image areas has been relevant for a specific class decision.\n","\n","LIME uses the quickshift algorithm to produce these superpixels (more details here : https://www.robots.ox.ac.uk/~vedaldi/assets/pubs/vedaldi08quick.pdf)\n","\n","<p align=\"center\">\n","<img src=https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/figure3-2cea505fe733a4713eeff3b90f696507.jpg width=500>\n","</p>\n","\n","\n","\n","### 2. Generate perturbed instances :\n","Once the superpixels are defined, we can generate a new dataset of perturbed instances by turning off superpixels on the image. The interpretable representation of the image is a binary vector where 1 indicates the original super-pixel and 0 indicates a grayed out super-pixel.\n","\n","### 3. Fit a linear model on the samples\n","\n","We can now fit a linear model on the perturbed instance to a specific class and highlight the superpixels with positive or negative weight towards a specific class.\n","\n","<p align=\"center\">\n","<img src=https://www.oreilly.com/content/wp-content/uploads/sites/2/2019/06/figure4-99d9ea184dd35876e0dbae81f6fce038.jpg width=500>\n","</p>\n","\n","\n","# Now let's practice !\n","\n","## Packages installation & Imports\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDsDzZNlTPaO"},"outputs":[],"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from lime import lime_image\n","from skimage.segmentation import mark_boundaries\n","from keras.applications import inception_v3 as inc_net"]},{"cell_type":"markdown","metadata":{"id":"R0FyQuA7TZ3Q"},"source":["## InceptionV3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1WXAJZxoTPfz"},"outputs":[],"source":["inception_model = InceptionV3(weights='imagenet')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvGmMMGLTPi3"},"outputs":[],"source":["def transform_img_fn(path_list):\n","    out = []\n","    for img_path in path_list:\n","        img = image.load_img(img_path, target_size=(299, 299))\n","        x = image.img_to_array(img)\n","        x = np.expand_dims(x, axis=0)\n","        x = inc_net.preprocess_input(x)\n","        out.append(x)\n","    return np.vstack(out)\n","\n","images = transform_img_fn([\"/content/sample_data/cat_car.jpeg\"])"]},{"cell_type":"markdown","metadata":{"id":"EYqqN1GIvJ6n"},"source":["Display an image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xej91BUTPl0"},"outputs":[],"source":["plt.imshow(images[0] / 2 + 0.5)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Bm8ILUEHTipb"},"source":["Let's use Inceptionv3 on the image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c08vwHNETgdk"},"outputs":[],"source":["preds = inception_model.predict(images)\n","for x in decode_predictions(preds)[0]:\n","    print(x)"]},{"cell_type":"markdown","metadata":{"id":"km8zL3IyTozx"},"source":["Let's use LIME"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qX8tP21mTPtT"},"outputs":[],"source":["explainer = lime_image.LimeImageExplainer()\n","explanation = explainer.explain_instance(images[0].astype('double'), inception_model.predict, top_labels=5, hide_color=0, num_samples=200)"]},{"cell_type":"markdown","metadata":{"id":"O0Y10V3Ivasm"},"source":["Display the most important superpixels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXQcQctfTplX"},"outputs":[],"source":["selected_label = 0\n","temp, mask = explanation.get_image_and_mask(explanation.top_labels[selected_label], positive_only=True, num_features=5, hide_rest=True)\n","plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TcKWuh86Tpop"},"outputs":[],"source":["# Plot boundaries on the full image\n","temp, mask = explanation.get_image_and_mask(explanation.top_labels[selected_label], positive_only=True, num_features=5, hide_rest=False)\n","plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJUGfMHITpr_"},"outputs":[],"source":["ind =  explanation.top_labels[selected_label]\n","\n","dict_heatmap = dict(explanation.local_exp[ind])\n","heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)\n","\n","plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\n","plt.colorbar()"]},{"cell_type":"markdown","metadata":{"id":"53b4ac7c"},"source":["# **SH**apley **A**dditive ex**P**lanations ([Lundberg et .al 2017](https://arxiv.org/abs/1905.04610))\n","\n","## From Game Theory\n","\n","\n","* In game theory, the [Shapley value](https://en.wikipedia.org/wiki/Shapley_value) (1953) is a solution concept of fairly distributing both gains and costs to several actors working in coalition.\n","* The Shapley value applies primarily in situations when the contributions of each actor are unequal, but they work in cooperation with each other to obtain the payoff.\n","\n","You first start by identifying each player’s contribution when they play individually, when 2 play together, and when all 3 play together.\n","<p align=\"center\">\n","<img src=https://clearcode.cc/app/uploads/2016/11/ABC-wide.png width=500>\n","</p>\n","\n","Then, you need to consider all possible orders and calculate their marginal value – e.g. what value does each player add when player A enters the game first, followed by player B, and then player C.\n","Below are the 6 possible orders and the marginal value each player adds in the different combinations:\n","<p align=\"center\">\n","<img src=https://clearcode.cc/app/uploads/2016/11/ABC-updated.png width=500>\n","</p>\n","\n","Now that we have calculated each player’s marginal value across all 6 possible order combinations, we now need to add them up and work out the Shapley value (i.e. the average) for each player.\n","\n","<ins>Example for Player A:</ins>\n","$ \\text{Shapley}_{value} = \\frac{7+7+10+3+9+10}{6} \\approx 7.7$\n","\n","Computing the Shapley value for each player will give the true contribution each player made to the game and assign credit fairly\n","\n","## To Explainability Method\n","\n","* Each value of an independent variable or a feature for a given sample is a part of a cooperative game where we assume that prediction is actually the payout.\n","* Shapley values correspond to the contribution of each feature towards pushing the prediction away from the expected value.\n","\n","Let take an example of the median house value prediction for California districts\n","<p align=\"center\">\n","<img src=https://raw.githubusercontent.com/shap/shap/master/docs/artwork/california_waterfall.png width=700>\n","</p>\n","\n","Example of features definition:\n","* MedInc: median income in block group\n","* HouseAge: median house age in block group\n","* AveRooms: average number of rooms per household\n","* AveBedrms: average number of bedrooms per household\n","* Population: block group population\n","* AveOccup: average number of household members\n","* Latitude: block group latitude\n","* Longitude: block group longitude\n","\n","For more information, link to [California housing prices dataset](https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html)\n"]},{"cell_type":"markdown","metadata":{"id":"726ceb7c"},"source":["## Explanation of SHAP through visualization\n","\n","### Global explainability & local explanation summary\n","<p align=\"center\">\n","<img src=https://raw.githubusercontent.com/shap/shap/master/docs/artwork/california_global_bar.png width=470>\n","<img src=https://raw.githubusercontent.com/shap/shap/master/docs/artwork/california_beeswarm.png width=530>\n","</p>\n","\n","### Local explainability and correlation\n","<p align=\"center\">\n","<img src=https://raw.githubusercontent.com/shap/shap/master/docs/artwork/california_scatter.png width=500>\n","</p>\n","\n","## Advantages\n","* SHAP has a solid theoretical foundation in game theory. The prediction is fairly distributed among the feature values. We get contrastive explanations that compare the prediction with the average prediction.\n","* SHAP has a fast implementation for tree-based models.\n","* When computation of the many Shapley values is possible, global model interpretations can be built. The global interpretation methods include feature importance, feature dependence, interactions, clustering and summary plots.\n","\n","## Drawbacks\n","* Slow computation if you want to compute Shapley values for many instances (except for tree-based models).\n","* The disadvantages of Shapley values also apply to SHAP: Shapley values can be misinterpreted.\n","* Since every model is trained from observational data, it is not necessarily a causal model.\n","\n","For more information on SHAP values see: https://github.com/shap/shap"]},{"cell_type":"markdown","metadata":{"id":"YMFZVTiR5Vrm"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBsbQvdldRLb"},"outputs":[],"source":["! pip install shap\n","\n","import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","import shap\n","import matplotlib.pyplot as plt\n","\n","shap.initjs()"]},{"cell_type":"markdown","metadata":{"id":"jcWVDb2w5Zhe"},"source":["### Chargement des données"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMcIPsXnyeii"},"outputs":[],"source":["df = pd.read_csv(\"/content/sample_data/lyon_immo.csv\")\n","\n","X = df.drop([\"prix_eur\"], axis=1)\n","y = df[\"prix_eur\"]"]},{"cell_type":"code","source":["# UNCOMMENT IF RUNNING THE NOTEBOOK LOCALLY\n","\n","# df = pd.read_csv(\"..data/lyon_immo/lyon_immo.csv\")\n","\n","# X = df.drop([\"prix_eur\"], axis=1)\n","# y = df[\"prix_eur\"]"],"metadata":{"id":"DykJQv3NQeuW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"j5CHd3VIPmgd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cYCdLg05bXH"},"source":["### Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gy8RKzIk1hDZ"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"]},{"cell_type":"markdown","metadata":{"id":"0R9araq65dNi"},"source":["Define a preprocessor with a OneHotEncoder for categorical features, and a Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TjJiikI0y6pj"},"outputs":[],"source":["from sklearn import compose, pipeline, preprocessing, ensemble\n","\n","cat_cols = [\"quartier\", \"etat_bien\"]\n","\n","preprocessor = compose.ColumnTransformer(\n","    ### TODO ###\n",")\n","\n","model = ### TODO ###\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sahq_sxA1k1w"},"outputs":[],"source":["preprocessor.fit(X_train)\n","X_train = pd.DataFrame(preprocessor.transform(X_train), columns=preprocessor.get_feature_names_out())\n","X_test = pd.DataFrame(preprocessor.transform(X_test), columns=preprocessor.get_feature_names_out())"]},{"cell_type":"markdown","metadata":{"id":"Hwr-IUrd5jPk"},"source":["Train the Random forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8aumw7Hq2Ye3"},"outputs":[],"source":["model.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"b7qF_dB76Vde"},"source":["Evaluate its performances"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OTKXpAT5uLo"},"outputs":[],"source":["metric = metrics.get_scorer(\"neg_mean_absolute_error\")\n","score = metric(model, X_train, y_train)\n","print(\"MAE train : \" + str(round(score)))\n","score = metric(model, X_test, y_test)\n","print(\"MAE test : \" + str(round(score)))"]},{"cell_type":"markdown","metadata":{"id":"ONM2ckRT5oOI"},"source":["Let's use SHAP to explain the predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46jVtJO_2X_H"},"outputs":[],"source":["explainer = shap.TreeExplainer(model)\n","explainer_X_test = explainer(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmEiT61M2hTR"},"outputs":[],"source":["shap_values = explainer_X_test.values\n","base_values = explainer_X_test.base_values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PbfH46jy2iA_"},"outputs":[],"source":["exp = shap.Explanation(shap_values, base_values, data=X_test.values, feature_names=X_test.columns)\n","\n","idx=2\n","\n","shap.plots.waterfall(exp[idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuNtCoHq2n1W"},"outputs":[],"source":["shap.initjs()\n","shap.force_plot(explainer.expected_value, shap_values[idx,:], X_test.iloc[idx,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ulscmE-2sO4"},"outputs":[],"source":["shap.plots.bar(explainer_X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcnQB3Mf22su"},"outputs":[],"source":["shap.summary_plot(shap_values, X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAI5gmxz23H-"},"outputs":[],"source":["shap.dependence_plot(\"remainder__surface_m2\", shap_values, X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9J0ZaM6u32Cf"},"outputs":[],"source":["top_inds = np.argsort(-np.sum(np.abs(shap_values), 0))\n","\n","for i in range(3):\n","    shap.dependence_plot(top_inds[i], shap_values, X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R9KXzeNh4NUk"},"outputs":[],"source":["shap.dependence_plot(top_inds[3], shap_values, X_test, x_jitter=0.5, alpha=0.8, dot_size=5)"]},{"cell_type":"markdown","metadata":{"id":"f742aa2e"},"source":["## Going further with Explainability\n","\n","### SHAPASH ([Github](https://github.com/MAIF/shapash))\n","\n","A module developped by MAIF using SHAP methodology with nice features such as a web app for exploration and ML OPS usage.\n","\n","[Demo](https://shapash-demo.ossbymaif.fr/) of the dashboarding capabilities.\n","\n","[Notebook](https://github.com/MAIF/shapash/blob/master/tutorial/tutorial03-Shapash-overview-model-in-production.ipynb) example for ML OPS usage\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1YkKfykDo4IWY8fsPiswbXKV_XB032LT4","timestamp":1763491178915}]},"kernelspec":{"display_name":"dev","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}