{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png\" /></a>&nbsp;| Luca Mossina and [Emmanuel Rachelson](https://personnel.isae-supaero.fr/emmanuel-rachelson?lang=en) | <a href=\"https://supaerodatascience.github.io/machine-learning/\">https://supaerodatascience.github.io/machine-learning/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f04d09ee-0e3c-4a24-b3ce-345323c1ce23"
    }
   },
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">An application of SVMs in Multi-Label Classification (MLC)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see an application which is both harder and less common than binary classification, that of **multi-label classification** (MLC).  \n",
    "Given a list of possible labels, the problem consists in finding one **or more** labels associated to a data point.  \n",
    "For instance, imagine extracting the key topics from a newspaper article, or classifing the elements composing an image. Possibly many labels can be associated to each item.\n",
    "\n",
    "Given a set of labels $\\mathcal{L} = \\{l_1, l_2, ..., l_k\\} \\in \\{0,1\\}^k$, we want to map elements of a feature space $\\mathcal{X}$ to a subset of $\\mathcal{L}$:  \n",
    "\n",
    "$$h : \\mathcal{X} \\longrightarrow \\mathcal{P}(\\mathcal{L})$$\n",
    "\n",
    "The two typical approaches for such problems are known as **Binary Relevance** (BR) and **Label Powerset** (LP).  \n",
    "\n",
    " - BR: each label in $\\mathcal{L}$ is a binary classification problem, $h_{i} : \\mathcal{X} \\longrightarrow l_{i}, l_{i} \\in \\{0,1\\}, i = 1, ..., |\\mathcal{L}|$.  \n",
    " This method ignores any correlation between labels (supposes them independent).\n",
    "\n",
    " - LP: transforms a problem of MLC into one of multiclass classification, mapping elements $x \\in \\mathcal{X}$ directly to $s \\in \\mathcal{P}(\\mathcal{L})$.  \n",
    " This method becomes rapidly inapplicable as the number of elemnts in $\\mathcal{P}(\\mathcal{L})$ grows exponentially with the number of labels.\n",
    " \n",
    "If you are curious on the topic of MLC, you are encouraged to read these references:  \n",
    "J. Read, P. Reutemann, B. Pfahringer, and Geoff Holmes. **MEKA: A multi-label/multi-target extension to Weka**. Journal of Machine Learning Research, 17(21):1-5, 2016.  \n",
    "G. Tsoumakas and I. Katakis. **Multi-label classification: An overview**. International Journal on Data Warehousing and Mining, 3(3):1-13, 2007.  \n",
    "G. Tsoumakas, I. Katakis, and I. Vlahavas. **Mining multi-label data**. Data mining and knowledge discovery handbook, pages 667-685. Springer, 2010.\n",
    " \n",
    "Many other variations exist, but for today we'll focus on BR, the most straightforward to implement. What we will start implementing below is a good start if you want to explore what is done in:  \n",
    "J. Read, B. Pfahringer, G. Holmes, and E. Frank. **Classifier chains for multi-label classification**. Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 254-269, 2009.\n",
    "\n",
    "The equivalent approach for LP is found in:  \n",
    "G. Tsoumakas, I. Katakis, and I. Vlahavas. **Random k-labelsets for multi-label classification**. IEEE Transactions on Knowledge and Data Engineering, 23(7):1079-1089, 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will use a biology dataset from [Elisseeff and Weston 2001]: this dataset contains micro-array expressions and phylogenetic profiles for 2417 yeast genes. Each gene is annotated with a subset of 14 functional categories (e.g. metabolism, energy, etc.) of the top level of the functional catalogue.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice**<br>\n",
    "<ul>\n",
    "\n",
    "<li> find a suitable package to load the file at `yeast.arff`.  <br>\n",
    "    Hint: <a href=https://docs.scipy.org/doc/scipy/reference/io.html>scipy.io</a> and _read the doc_.<br>\n",
    "<li> Store the data in a pandas dataframe.<br>\n",
    "    Hint: columns of classes will be encoded as 'utf-8', we need integers, look for 'str.decode('utf-8')'\n",
    "<li> check dataset: you should have 2417 samples $\\times$ 117 columns (103 features + 14 labels)\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from scipy.io import arff\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "from utils import shuffle_and_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class1</th>\n",
       "      <th>Class2</th>\n",
       "      <th>Class3</th>\n",
       "      <th>Class4</th>\n",
       "      <th>Class5</th>\n",
       "      <th>Class6</th>\n",
       "      <th>Class7</th>\n",
       "      <th>Class8</th>\n",
       "      <th>Class9</th>\n",
       "      <th>Class10</th>\n",
       "      <th>...</th>\n",
       "      <th>Att94</th>\n",
       "      <th>Att95</th>\n",
       "      <th>Att96</th>\n",
       "      <th>Att97</th>\n",
       "      <th>Att98</th>\n",
       "      <th>Att99</th>\n",
       "      <th>Att100</th>\n",
       "      <th>Att101</th>\n",
       "      <th>Att102</th>\n",
       "      <th>Att103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039048</td>\n",
       "      <td>-0.018712</td>\n",
       "      <td>-0.034711</td>\n",
       "      <td>-0.038675</td>\n",
       "      <td>-0.039102</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>-0.052659</td>\n",
       "      <td>-0.042402</td>\n",
       "      <td>0.118473</td>\n",
       "      <td>0.125632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001198</td>\n",
       "      <td>0.030594</td>\n",
       "      <td>-0.021814</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>-0.013809</td>\n",
       "      <td>-0.009248</td>\n",
       "      <td>-0.027318</td>\n",
       "      <td>-0.014191</td>\n",
       "      <td>0.022783</td>\n",
       "      <td>0.123785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195777</td>\n",
       "      <td>0.022294</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>-0.002072</td>\n",
       "      <td>-0.010981</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>-0.063378</td>\n",
       "      <td>-0.084181</td>\n",
       "      <td>-0.034402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>-0.066241</td>\n",
       "      <td>-0.046999</td>\n",
       "      <td>-0.066604</td>\n",
       "      <td>-0.055773</td>\n",
       "      <td>-0.041941</td>\n",
       "      <td>0.051066</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.193972</td>\n",
       "      <td>0.131866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035045</td>\n",
       "      <td>-0.080882</td>\n",
       "      <td>0.028468</td>\n",
       "      <td>-0.073576</td>\n",
       "      <td>0.050630</td>\n",
       "      <td>0.084832</td>\n",
       "      <td>-0.019570</td>\n",
       "      <td>-0.021650</td>\n",
       "      <td>-0.068326</td>\n",
       "      <td>-0.091155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030530</td>\n",
       "      <td>-0.025955</td>\n",
       "      <td>-0.023820</td>\n",
       "      <td>-0.027757</td>\n",
       "      <td>-0.021961</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>-0.027194</td>\n",
       "      <td>-0.023020</td>\n",
       "      <td>0.021652</td>\n",
       "      <td>0.137082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>-0.007117</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>-0.011406</td>\n",
       "      <td>-0.017818</td>\n",
       "      <td>-0.004101</td>\n",
       "      <td>-0.046161</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>0.060844</td>\n",
       "      <td>0.137526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053868</td>\n",
       "      <td>-0.057654</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>-0.057880</td>\n",
       "      <td>0.171701</td>\n",
       "      <td>0.045545</td>\n",
       "      <td>-0.051639</td>\n",
       "      <td>-0.038713</td>\n",
       "      <td>-0.026947</td>\n",
       "      <td>0.005620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040829</td>\n",
       "      <td>-0.055524</td>\n",
       "      <td>0.018662</td>\n",
       "      <td>-0.053545</td>\n",
       "      <td>-0.056904</td>\n",
       "      <td>-0.045714</td>\n",
       "      <td>-0.039205</td>\n",
       "      <td>-0.019985</td>\n",
       "      <td>0.280843</td>\n",
       "      <td>0.143382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062109</td>\n",
       "      <td>-0.005209</td>\n",
       "      <td>-0.037392</td>\n",
       "      <td>0.056707</td>\n",
       "      <td>-0.060944</td>\n",
       "      <td>-0.056202</td>\n",
       "      <td>-0.069893</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>-0.041307</td>\n",
       "      <td>-0.146233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2417 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class1 Class2 Class3 Class4 Class5 Class6 Class7 Class8 Class9 Class10  \\\n",
       "0      b'0'   b'0'   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "1      b'0'   b'0'   b'0'   b'0'   b'0'   b'0'   b'1'   b'1'   b'0'    b'0'   \n",
       "2      b'0'   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "3      b'0'   b'0'   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "4      b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "2412   b'1'   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "2413   b'1'   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "2414   b'1'   b'1'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'   b'0'    b'0'   \n",
       "2415   b'0'   b'1'   b'1'   b'0'   b'0'   b'0'   b'1'   b'1'   b'0'    b'0'   \n",
       "2416   b'1'   b'1'   b'0'   b'0'   b'0'   b'1'   b'1'   b'0'   b'0'    b'0'   \n",
       "\n",
       "      ...     Att94     Att95     Att96     Att97     Att98     Att99  \\\n",
       "0     ...  0.039048 -0.018712 -0.034711 -0.038675 -0.039102  0.017429   \n",
       "1     ... -0.001198  0.030594 -0.021814  0.010430 -0.013809 -0.009248   \n",
       "2     ...  0.195777  0.022294  0.012583  0.002233 -0.002072 -0.010981   \n",
       "3     ...  0.001189 -0.066241 -0.046999 -0.066604 -0.055773 -0.041941   \n",
       "4     ... -0.035045 -0.080882  0.028468 -0.073576  0.050630  0.084832   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "2412  ...  0.030530 -0.025955 -0.023820 -0.027757 -0.021961  0.007489   \n",
       "2413  ...  0.000522 -0.007117 -0.025083 -0.011406 -0.017818 -0.004101   \n",
       "2414  ... -0.053868 -0.057654  0.006976 -0.057880  0.171701  0.045545   \n",
       "2415  ...  0.040829 -0.055524  0.018662 -0.053545 -0.056904 -0.045714   \n",
       "2416  ... -0.062109 -0.005209 -0.037392  0.056707 -0.060944 -0.056202   \n",
       "\n",
       "        Att100    Att101    Att102    Att103  \n",
       "0    -0.052659 -0.042402  0.118473  0.125632  \n",
       "1    -0.027318 -0.014191  0.022783  0.123785  \n",
       "2     0.007615 -0.063378 -0.084181 -0.034402  \n",
       "3     0.051066  0.004976  0.193972  0.131866  \n",
       "4    -0.019570 -0.021650 -0.068326 -0.091155  \n",
       "...        ...       ...       ...       ...  \n",
       "2412 -0.027194 -0.023020  0.021652  0.137082  \n",
       "2413 -0.046161 -0.011562  0.060844  0.137526  \n",
       "2414 -0.051639 -0.038713 -0.026947  0.005620  \n",
       "2415 -0.039205 -0.019985  0.280843  0.143382  \n",
       "2416 -0.069893  0.006505 -0.041307 -0.146233  \n",
       "\n",
       "[2417 rows x 117 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_yeast = '../data/yeast/yeast.arff'\n",
    "\n",
    "arff_file = arff.loadarff(path_to_yeast)\n",
    "df = pd.DataFrame(arff_file[0])\n",
    "\n",
    "assert(df.shape == (2417, 117))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Exercice**<br>\n",
    "<ul>\n",
    "<li> Manually, fit a SVM classifier for each label in the dataset\n",
    "<li> Apply a cross-validation of 60 ∕ 40: 60% of datapoints to train the model, 40% to test it  <br>\n",
    "   Remember: it is good practice to <b>randomly shuffle</b> the data, in case the data are ordered w.r.t. some data-dependent criterion.\n",
    "<li> Report some performance measure\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Class1': {'poly': 0.7807652533609101, 'linear': 0.7859358841778697, 'rbf': 0.7942088934850051, 'sigmoid': 0.749741468459152}, 'Class2': {'poly': 0.656670113753878, 'linear': 0.6204756980351603, 'rbf': 0.6546018614270941, 'sigmoid': 0.5873836608066184}, 'Class3': {'poly': 0.7197518097207859, 'linear': 0.7094105480868665, 'rbf': 0.7290589451913133, 'sigmoid': 0.6659772492244054}, 'Class4': {'poly': 0.7280248190279214, 'linear': 0.7228541882109617, 'rbf': 0.7445708376421923, 'sigmoid': 0.656670113753878}, 'Class5': {'poly': 0.781799379524302, 'linear': 0.7538779731127198, 'rbf': 0.7942088934850051, 'sigmoid': 0.6597724922440538}, 'Class6': {'poly': 0.7766287487073423, 'linear': 0.749741468459152, 'rbf': 0.7724922440537746, 'sigmoid': 0.7383660806618407}, 'Class7': {'poly': 0.828335056876939, 'linear': 0.8200620475698035, 'rbf': 0.827300930713547, 'sigmoid': 0.8159255429162358}, 'Class8': {'poly': 0.8086866597724922, 'linear': 0.8035160289555325, 'rbf': 0.8066184074457083, 'sigmoid': 0.7859358841778697}, 'Class9': {'poly': 0.9286452947259566, 'linear': 0.9286452947259566, 'rbf': 0.9286452947259566, 'sigmoid': 0.9286452947259566}, 'Class10': {'poly': 0.8934850051706308, 'linear': 0.890382626680455, 'rbf': 0.8924508790072389, 'sigmoid': 0.890382626680455}, 'Class11': {'poly': 0.8800413650465356, 'linear': 0.8769389865563598, 'rbf': 0.8790072388831437, 'sigmoid': 0.8769389865563598}, 'Class12': {'poly': 0.7414684591520165, 'linear': 0.7425025853154085, 'rbf': 0.7394002068252327, 'sigmoid': 0.7156153050672182}, 'Class13': {'poly': 0.733195449844881, 'linear': 0.734229576008273, 'rbf': 0.734229576008273, 'sigmoid': 0.6990692864529473}, 'Class14': {'poly': 0.9917269906928645, 'linear': 0.9917269906928645, 'rbf': 0.9917269906928645, 'sigmoid': 0.9917269906928645}}\n"
     ]
    }
   ],
   "source": [
    "df = df.replace({b'0': 0, b'1': 1})\n",
    "\n",
    "label_names = [column for column in df.columns if 'Class' in column]\n",
    "feature_names = [column for column in df.columns if 'Att' in column]\n",
    "\n",
    "accuracy_kernel_label = {label: {} for label in label_names}\n",
    "\n",
    "\n",
    "for label in label_names:\n",
    "    available_kernel = ['poly', 'linear', 'rbf', 'sigmoid']\n",
    "    accuracy_kernel = {kernel: 0 for kernel in available_kernel}\n",
    "\n",
    "    X = df[feature_names]\n",
    "    y = df[label]\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = shuffle_and_split(X, y, 0.6)\n",
    "    \n",
    "    for kernel in available_kernel:\n",
    "        svm_model = svm.SVC(kernel=kernel, C= 1.)\n",
    "        svm_model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = svm_model.predict(X_test)\n",
    "        accuracy_kernel[kernel] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    accuracy_kernel_label[label] = accuracy_kernel\n",
    "    \n",
    "print(accuracy_kernel_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Class1': ('rbf', 0.7942088934850051), 'Class2': ('poly', 0.656670113753878), 'Class3': ('rbf', 0.7290589451913133), 'Class4': ('rbf', 0.7445708376421923), 'Class5': ('rbf', 0.7942088934850051), 'Class6': ('poly', 0.7766287487073423), 'Class7': ('poly', 0.828335056876939), 'Class8': ('poly', 0.8086866597724922), 'Class9': ('poly', 0.9286452947259566), 'Class10': ('poly', 0.8934850051706308), 'Class11': ('poly', 0.8800413650465356), 'Class12': ('linear', 0.7425025853154085), 'Class13': ('linear', 0.734229576008273), 'Class14': ('poly', 0.9917269906928645)}\n"
     ]
    }
   ],
   "source": [
    "best_kernel_scores = {}\n",
    "\n",
    "for label, kernel_scores in accuracy_kernel_label.items():\n",
    "    best_kernel = max(kernel_scores, key=kernel_scores.get)\n",
    "    best_score = kernel_scores[best_kernel]\n",
    "    \n",
    "    best_kernel_scores[label] = (best_kernel, best_score)\n",
    "\n",
    "print(best_kernel_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Class1': 'rbf', 'Class2': 'rbf', 'Class3': 'rbf', 'Class4': 'rbf', 'Class5': 'rbf', 'Class6': 'poly', 'Class7': 'poly', 'Class8': 'poly', 'Class9': 'poly', 'Class10': 'poly', 'Class11': 'poly', 'Class12': 'poly', 'Class13': 'poly', 'Class14': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Define the range of C values to search over\n",
    "available_kernel = ['poly', 'linear', 'rbf', 'sigmoid']\n",
    "\n",
    "# Create a dictionary to store the best C values for each label\n",
    "best_kernel_values = {}\n",
    "\n",
    "for label in label_names:\n",
    "    # Define X and y for the current label\n",
    "    X_label = df[feature_names]\n",
    "    y_label = df[label]\n",
    "    \n",
    "    # Define the SVM model\n",
    "    svm_model = svm.SVC(C= 1.)  # Use the best kernel\n",
    "\n",
    "    # Specify the desired training-to-testing ratio\n",
    "    train_size = 0.6\n",
    "    \n",
    "    # Set up Stratified Shuffle Split with the desired ratio\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, train_size=train_size, test_size=1-train_size, random_state=42)\n",
    "    \n",
    "    # Perform GridSearchCV to find the best C value\n",
    "    param_grid = {'kernel': available_kernel}\n",
    "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_label, y_label)\n",
    "    \n",
    "    # Store the best C value in the dictionary\n",
    "    best_kernel_values[label] = grid_search.best_params_['kernel']\n",
    "\n",
    "print(best_kernel_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Class1': 1, 'Class2': 1, 'Class3': 1, 'Class4': 1, 'Class5': 1, 'Class6': 1, 'Class7': 1, 'Class8': 1, 'Class9': 0.01, 'Class10': 1, 'Class11': 1, 'Class12': 1, 'Class13': 1, 'Class14': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Define the range of C values to search over\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Create a dictionary to store the best C values for each label\n",
    "best_C_values = {}\n",
    "\n",
    "for label in label_names:\n",
    "    # Define X and y for the current label\n",
    "    X_label = df[feature_names]\n",
    "    y_label = df[label]\n",
    "    \n",
    "    # Define the SVM model\n",
    "    svm_model = svm.SVC(kernel=best_kernel_values[label])  # Use the best kernel\n",
    "\n",
    "    # Specify the desired training-to-testing ratio\n",
    "    train_size = 0.6\n",
    "    \n",
    "    # Set up Stratified Shuffle Split with the desired ratio\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, train_size=train_size, test_size=1-train_size, random_state=42)\n",
    "    \n",
    "    # Perform GridSearchCV to find the best C value\n",
    "    param_grid = {'C': C_values}\n",
    "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_label, y_label)\n",
    "    \n",
    "    # Store the best C value in the dictionary\n",
    "    best_C_values[label] = grid_search.best_params_['C']\n",
    "\n",
    "print(best_C_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try both mixed (with targeted C):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of C values to search over\n",
    "C_values = [0.005, 0.01, 0.05, 0.08, 0.1, 0.5, 0.75, 1, 2, 3]\n",
    "available_kernel = ['poly', 'linear', 'rbf', 'sigmoid']\n",
    "\n",
    "# Create a dictionary to store the best C values for each label\n",
    "best_kernel_and_C_values = {}\n",
    "\n",
    "for label in label_names:\n",
    "    # Define X and y for the current label\n",
    "    X_label = df[feature_names]\n",
    "    y_label = df[label]\n",
    "    \n",
    "    # Define the SVM model\n",
    "    svm_model = svm.SVC()\n",
    "\n",
    "    # Specify the desired training-to-testing ratio\n",
    "    train_size = 0.6\n",
    "    \n",
    "    # Set up Stratified Shuffle Split with the desired ratio\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, train_size=train_size, test_size=1-train_size, random_state=42)\n",
    "    \n",
    "    # Perform GridSearchCV to find the best C value\n",
    "    param_grid = {'C': C_values, 'kernel': available_kernel}\n",
    "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_label, y_label)\n",
    "    \n",
    "    # Store the best C value in the dictionary\n",
    "    best_kernel_and_C_values[label] = (grid_search.best_params_['kernel'], grid_search.best_params_['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Class1': ('rbf', 1), 'Class2': ('rbf', 1), 'Class3': ('rbf', 0.5), 'Class4': ('rbf', 1), 'Class5': ('rbf', 1), 'Class6': ('rbf', 2), 'Class7': ('rbf', 2), 'Class8': ('poly', 1), 'Class9': ('poly', 2), 'Class10': ('rbf', 2), 'Class11': ('poly', 2), 'Class12': ('poly', 1), 'Class13': ('poly', 1), 'Class14': ('poly', 0.005)}\n"
     ]
    }
   ],
   "source": [
    "print(best_kernel_and_C_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-Averaged Precision: 0.8028199574029516\n",
      "Micro-Averaged Recall: 0.357655718431777\n",
      "Micro-Averaged F1-Score: 0.39793720199452565\n",
      "Micro-Averaged Hamming Loss: 0.18496085093810016\n",
      "\n",
      "\n",
      "\n",
      "Label: Class1\n",
      "Model chosen : (kernel: rbf, C: 1)\n",
      "Precision: 0.770949720670391\n",
      "Recall: 0.4524590163934426\n",
      "F1-Score: 0.5702479338842975\n",
      "Hamming Loss: 0.21509824198552224\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class2\n",
      "Model chosen : (kernel: rbf, C: 1)\n",
      "Precision: 0.6886792452830188\n",
      "Recall: 0.522673031026253\n",
      "F1-Score: 0.5943012211668929\n",
      "Hamming Loss: 0.30920372285418823\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class3\n",
      "Model chosen : (kernel: rbf, C: 0.5)\n",
      "Precision: 0.7197802197802198\n",
      "Recall: 0.6717948717948717\n",
      "F1-Score: 0.6949602122015915\n",
      "Hamming Loss: 0.2378490175801448\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class4\n",
      "Model chosen : (kernel: rbf, C: 1)\n",
      "Precision: 0.7981220657276995\n",
      "Recall: 0.4748603351955307\n",
      "F1-Score: 0.5954465849387041\n",
      "Hamming Loss: 0.23888314374353672\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class5\n",
      "Model chosen : (kernel: rbf, C: 1)\n",
      "Precision: 0.9047619047619048\n",
      "Recall: 0.3944636678200692\n",
      "F1-Score: 0.5493975903614459\n",
      "Hamming Loss: 0.19338159255429163\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class6\n",
      "Model chosen : (kernel: rbf, C: 2)\n",
      "Precision: 0.7162162162162162\n",
      "Recall: 0.21115537848605578\n",
      "F1-Score: 0.3261538461538462\n",
      "Hamming Loss: 0.2264736297828335\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class7\n",
      "Model chosen : (kernel: rbf, C: 2)\n",
      "Precision: 0.7105263157894737\n",
      "Recall: 0.14516129032258066\n",
      "F1-Score: 0.24107142857142858\n",
      "Hamming Loss: 0.17580144777662876\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class8\n",
      "Model chosen : (kernel: poly, C: 1)\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.04145077720207254\n",
      "F1-Score: 0.0792079207920792\n",
      "Hamming Loss: 0.1923474663908997\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class9\n",
      "Model chosen : (kernel: poly, C: 2)\n",
      "Precision: 1.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Hamming Loss: 0.06928645294725956\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class10\n",
      "Model chosen : (kernel: rbf, C: 2)\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 0.058823529411764705\n",
      "F1-Score: 0.11009174311926605\n",
      "Hamming Loss: 0.10031023784901758\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class11\n",
      "Model chosen : (kernel: poly, C: 2)\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.048\n",
      "F1-Score: 0.08955223880597014\n",
      "Hamming Loss: 0.12616339193381593\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class12\n",
      "Model chosen : (kernel: poly, C: 1)\n",
      "Precision: 0.7640918580375783\n",
      "Recall: 0.9932157394843962\n",
      "F1-Score: 0.863716814159292\n",
      "Hamming Loss: 0.23888314374353672\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class13\n",
      "Model chosen : (kernel: poly, C: 1)\n",
      "Precision: 0.7536534446764092\n",
      "Recall: 0.9931224209078404\n",
      "F1-Score: 0.8569732937685459\n",
      "Hamming Loss: 0.24922440537745605\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Label: Class14\n",
      "Model chosen : (kernel: poly, C: 0.005)\n",
      "Precision: 1.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Hamming Loss: 0.016546018614270942\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize dictionaries to store performance metrics for each label\n",
    "precision_scores = {}\n",
    "recall_scores = {}\n",
    "f1_scores = {}\n",
    "hamming_losses = {}\n",
    "\n",
    "# Iterate over each label\n",
    "for label in label_names:\n",
    "    X_label = df[feature_names]\n",
    "    y_label = df[label]\n",
    "\n",
    "    X_label, y_label = shuffle(X_label, y_label, random_state=42)\n",
    "    \n",
    "    # Split the dataset into a training and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_label, y_label, test_size=0.4, random_state=42)\n",
    "    \n",
    "    best_kernel, best_C = best_kernel_and_C_values[label]\n",
    "    \n",
    "    # Create a separate SVM model for the current label\n",
    "    svm_model = svm.SVC(kernel=best_kernel, C=best_C)\n",
    "    \n",
    "    # Train the model on the training set for the current label\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set for the current label\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, F1-score, and Hamming Loss for the current label\n",
    "    precision_scores[label] = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall_scores[label] = recall_score(y_test, y_pred, zero_division=1)\n",
    "    f1_scores[label] = f1_score(y_test, y_pred, zero_division=1)\n",
    "    hamming_losses[label] = hamming_loss(y_test, y_pred)\n",
    "\n",
    "# Calculate micro-averaged performance metrics\n",
    "micro_precision = np.mean(list(precision_scores.values()))\n",
    "micro_recall = np.mean(list(recall_scores.values()))\n",
    "micro_f1 = np.mean(list(f1_scores.values()))\n",
    "micro_hamming = np.mean(list(hamming_losses.values()))\n",
    "\n",
    "print(\"Micro-Averaged Precision:\", micro_precision)\n",
    "print(\"Micro-Averaged Recall:\", micro_recall)\n",
    "print(\"Micro-Averaged F1-Score:\", micro_f1)\n",
    "print(\"Micro-Averaged Hamming Loss:\", micro_hamming)\n",
    "print('\\n\\n')\n",
    "\n",
    "# Print performance metrics for each label\n",
    "for label in label_names:\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Model chosen : (kernel: {best_kernel_and_C_values[label][0]}, C: {best_kernel_and_C_values[label][1]})\")\n",
    "    print(\"Precision:\", precision_scores[label])\n",
    "    print(\"Recall:\", recall_scores[label])\n",
    "    print(\"F1-Score:\", f1_scores[label])\n",
    "    print(\"Hamming Loss:\", hamming_losses[label])\n",
    "    print('\\n-----------------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations**, you reached the end of the practice session! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
